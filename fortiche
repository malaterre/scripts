#!/usr/bin/env python3
# smartypants script

import argparse
import requests
import os
import json
# from bs4 import BeautifulSoup
import bs4 as bs
# from http import cookies
import urllib.parse
# https://stackoverflow.com/questions/44503833/python-slimit-minimizer-unwanted-warning-output
import logging
# FIXME: slimit replaced by python3-calmjs in Debian/sid
# sudo apt-get install aspell-fr

# TODO: 'oe' without spell check ? (Eg. Joe Dalton)

espace_insecable = ' '
espace_fine_insecable = ' '
tiret_moyen = '–'
tiret_court = '‐'


def whitespacify(s):
    if ".." in s or "'" in s:
        print("ERROR", s)
        sys.exit(1)
    # do not change whitespace around tirets
    s = s.replace(espace_insecable, ' ').replace(espace_fine_insecable, ' ')
    # symbols = [',', '.', '’', ';', '?', '!', '%', '€', '$', '«', '»', ':', '°']
    symbols = [',', '’', ';', '?', '!', '%', '€', '$', '«', '»', ':', '°']
    for symbol in symbols:
        s = s.replace(symbol, ' ' + symbol + ' ')
    while "  " in s:
        s = s.replace("  ", " ")
    return s.strip()


def cleanup(s):
    s = s.replace("'", "’").replace("...", "…")
    # english quotes:
    s = s.replace('“', '«').replace('”', '»')
    # chevrons
    while s.count('"') > 0 and s.count('"') % 2 == 0:
        s = s.replace('"', '«', 1).replace('"', '»', 1)
    # after ellipsis + chevrons
    s = whitespacify(s)
    # tiret moyen "–" (U+2013) Proposition incise
    if " - " in s:
        s = s.replace(" - ", " – ")
    # tiret court hypen "‐" (U+2010)  trait d’union
    if "-" in s:
        s = s.replace("-", "‐")
    # https://archive.framalibre.org/article2225.html
    if " ," in s:
        s = s.replace(" ,", ",")
    if s[-2:] == ' …':
        s = s[:-2] + "…"
    # ellipse have been taken care of
    if " ." in s:
        s = s.replace(" .", ".")
    if " ’ " in s:
        s = s.replace(" ’ ", "’")
    # https://fr.wikipedia.org/wiki/Espace_ins%C3%A9cable#En_France
    if " ;" in s:
        s = s.replace(" ;", espace_fine_insecable + ";")
    if " ?" in s:
        s = s.replace(" ?", espace_fine_insecable + "?")
    if " !" in s:
        s = s.replace(" !", espace_fine_insecable + "!")
    if " %" in s:
        s = s.replace(" %", espace_fine_insecable + "%")
    if " €" in s:
        s = s.replace(" €", espace_fine_insecable + "€")
    if " $" in s:
        s = s.replace(" $", espace_fine_insecable + "$")
    # exceptions:
    if "« " in s:
        s = s.replace("« ", "«" + espace_insecable)
    if " »" in s:
        s = s.replace(" »",  espace_insecable + "»")
    if " :" in s:
        s = s.replace(" :", espace_insecable + ":")
    # special:
    if " ° " in s:
        s = s.replace(" ° ", "°")
    return s


SIMPLE_INPUT_TYPES = ('text', 'hidden', 'password', 'submit',
                      'image', 'search', 'number', 'email', 'url')


def extract_form_fields(soup):  # pragma: no cover  # noqa (C901)
    # Based on https://gist.github.com/simonw/104413
    "Turn a BeautifulSoup form in to a dict of fields and default values"
    fields = {}
    for input in soup.findAll('input'):
        name = input.get("name")
        value = input.get("value")
        type = input.get("type", "text")
        if not name:
            continue

        if type in SIMPLE_INPUT_TYPES:
            fields[name] = value
            continue

        if type in ('checkbox', 'radio'):
            if input.get('checked'):
                value = (value or "on")

            if value:
                fields[name] = value
            else:
                fields.setdefault(name, value)
            continue

        assert False, 'input type %s not supported' % type

    for textarea in soup.findAll('textarea'):
        name = textarea.get("name")
        if name:
            fields[name] = (textarea.string or '')

    # select fields
    for select in soup.findAll('select'):
        options = select.findAll('option')
        selected_options = [
            option for option in options
            if option.has_attr('selected')
        ]

        if not selected_options and options:
            selected_options = [options[0]]

        value = [option['value']
                 for option in selected_options if option["value"]]

        fields[select['name']] = value

    return fields


def extract_form_fields2(soup):
    "Turn a BeautifulSoup form in to a dict of fields and default values"
    fields = {}
    for input in soup.findAll('input'):
        # ignore submit/image with no name attribute
        if not 'type' in input:
            continue
        if input['type'] in ('submit', 'image') and not 'name' in input:
            continue

        # single element name/value fields
        if input['type'] in ('text', 'hidden', 'password', 'submit', 'image'):
            value = ''
            if 'value' in input:
                value = input['value']
            fields[input['name']] = value
            continue

        # checkboxes and radios
        if input['type'] in ('checkbox', 'radio'):
            value = ''
            if input.has_attr("checked"):
                if input.has_attr('value'):
                    value = input['value']
                else:
                    value = 'on'
            if 'name' in input and value:
                fields[input['name']] = value

            if not 'name' in input:
                fields[input['name']] = value

            continue

        assert False, 'input type %s not supported' % input['type']

    # textareas
    for textarea in soup.findAll('textarea'):
        fields[textarea['name']] = textarea.string or ''

    # select fields
    for select in soup.findAll('select'):
        value = ''
        options = select.findAll('option')
        is_multiple = select.has_attr('multiple')
        selected_options = [
            option for option in options
            if option.has_attr('selected')
        ]

        # If no select options, go with the first one
        if not selected_options and options:
            selected_options = [options[0]]

        if not is_multiple:
            assert(len(selected_options) < 2)
            if len(selected_options) == 1:
                value = selected_options[0]['value']
        else:
            value = [option['value'] for option in selected_options]

        fields[select['name']] = value

    return fields


def urlencode(s):
    return urllib.parse.quote(s)


def urldecode(s):
    return urllib.parse.unquote(s)


def encode_prefs(prefs):
    return urlencode(bytes(json.dumps(prefs, separators=(',', ':')), 'utf-8'))


def get_location(url):
    response = requests.head(url, allow_redirects=True)
    return response.url


def get_spoken_languages_from_script(script):
    logging.disable(logging.CRITICAL)
    # https://stackoverflow.com/questions/25111752/extracting-text-from-script-tag-using-beautifulsoup-in-python
    from slimit import ast
    from slimit.parser import Parser
    from slimit.visitors import nodevisitor

    fields = None
    parser = Parser()
    # https://github.com/rspivak/slimit/blob/master/src/slimit/ast.py
    tree = parser.parse(script.text)
    for node in nodevisitor.visit(tree):
        # ast.FunctionCall
        if isinstance(node, ast.FunctionCall):
            # slimit.ast.DotAccessor
            if isinstance(node.identifier, ast.DotAccessor):
                assert isinstance(node.identifier.identifier, ast.Identifier)
                if isinstance(node.identifier.identifier, ast.Identifier):
                    if node.identifier.identifier.value == 'kendoMultiSelect':
                        assert isinstance(node.args, list)
                        assert len(node.args) == 1
                        assert isinstance(node.args[0], ast.Object)
                        for properties in node.args[0].properties:
                            # slimit.ast.Assign
                            assert isinstance(properties, ast.Assign)
                            if isinstance(properties, ast.Assign):
                                if properties.left.value == 'value':
                                    fields = []
                                    for child in properties.right.children():
                                        assert isinstance(child, ast.Object)
                                        cc = child.properties
                                        assert len(cc) == 1
                                        assert isinstance(cc[0], ast.Assign)
                                        if isinstance(cc[0], ast.Assign):
                                            cclid = cc[0].left
                                            ccrid = cc[0].right
                                            assert isinstance(
                                                cclid, ast.Identifier)
                                            assert isinstance(
                                                ccrid, ast.String)
                                            assert cclid.value == 'iso_639_1'
                                            assert len(ccrid.value) >= 2
                                            # remove extra quotes char '"'
                                            s = ccrid.value[1:-1]
                                            fields.append(s)
    logging.disable(logging.NOTSET)
    return fields


def main(args):
    verbose = args.verbose
    movie_id = args.movie_id
    lang = args.lang
    dry_run = args.dry_run

    # url = 'https://www.themoviedb.org/movie/366644-little-door-gods/edit?active_nav_item=primary_facts'
    root_url = 'https://www.themoviedb.org/movie/'
    #    'referer': 'https://www.themoviedb.org/movie/9836-happy-feet/edit?active_nav_item=primary_facts',
    url = get_location(root_url + str(movie_id)) + \
        '/edit?active_nav_item=primary_facts'
    if verbose:
        print(url)

    headers = requests.utils.default_headers()
    tmdb_session = os.environ['TMDB_SESSION']

    cookies = {}
    tmdb_prefs = {"adult": True, "i18n_fallback_language": "en-US",
                  "locale": "fr-FR", "country_code": "FR", "timezone": "Europe/Paris"}
    cookies['tmdb.prefs'] = encode_prefs(tmdb_prefs)
    # cookies['tmdb.session'] # write access !!
    cookies['tmdb.session'] = tmdb_session
    # cookies['tmdb.prefs'] # default language (fr) !!
    cookie_string = "; ".join([str(x)+"="+str(y) for x, y in cookies.items()])
    headers['cookie'] = cookie_string
    r = requests.get(url, headers=headers)
    soup = bs.BeautifulSoup(r.content, 'html.parser')
    # if verbose:
    #    print(soup.prettify())
    # print(soup.find(id='primary_facts_form'))
    pff = soup.find(id='primary_facts_form')
    # if verbose:
    #    print(pff.prettify())
    # pff_next = pff.next_element
    if not pff:
        print("ERROR:" + movie_id)
    pff_script = pff.find_next('script', type="text/javascript")
    # if verbose:
    #     print(pff_script)
    spoken_languages = get_spoken_languages_from_script(pff_script)
    # print(spoken_languages)
    data = extract_form_fields(pff)
    if "spoken_languages[]" in data:
        data["spoken_languages[]"] = spoken_languages

    if verbose:
        print(json.dumps(data, indent=4, sort_keys=True))

    newdata = data.copy()
    if 'fr_FR_translated_title' in newdata:
        newdata['fr_FR_translated_title'] = cleanup(
            newdata['fr_FR_translated_title'])
    if 'fr_FR_overview' in newdata:
        newdata['fr_FR_overview'] = cleanup(
            newdata['fr_FR_overview'])
    if 'fr_FR_tagline' in newdata:
        newdata['fr_FR_tagline'] = cleanup(
            newdata['fr_FR_tagline'])

    if newdata != data:
        if verbose:
            print(json.dumps(newdata, indent=4, sort_keys=True))

        primary_facts = get_location(
            root_url + str(movie_id)) + '/remote/primary_facts'
        if not dry_run:
            response = requests.post(
                primary_facts, headers=headers, data=newdata)
            print(response)
    else:
        print('No diff')


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="tmdb typo")
    parser.add_argument("movie_id", help='movie id')
    #
    parser.add_argument("--dry-run",
                        help="dry run", action='store_true')
    # verbose
    parser.add_argument("--lang",
                        help="verbose output", action='store_true')
    parser.add_argument("--verbose",
                        help="verbose output", action='store_true')
    main(parser.parse_args())
